{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Install Dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-20T13:42:43.523678Z","iopub.status.busy":"2024-06-20T13:42:43.523196Z","iopub.status.idle":"2024-06-20T13:43:00.791081Z","shell.execute_reply":"2024-06-20T13:43:00.789702Z","shell.execute_reply.started":"2024-06-20T13:42:43.523638Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install \"comet_ml>=3.38.0\" torch torchvision tqdm &> /dev/null"]},{"cell_type":"markdown","metadata":{},"source":["# Initialize Comet"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-20T13:43:00.793450Z","iopub.status.busy":"2024-06-20T13:43:00.793072Z","iopub.status.idle":"2024-06-20T13:43:11.067461Z","shell.execute_reply":"2024-06-20T13:43:11.065981Z","shell.execute_reply.started":"2024-06-20T13:43:00.793417Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/mortezaomidi24/ml-tools-test/2c0660d88f954315abcde0cd6c53aa39\n","\n"]}],"source":["import comet_ml\n","from comet_ml.integration.pytorch import watch\n","from comet_ml import Experiment\n","\n","experiment = Experiment(\n","    api_key=\"add your comet API key\",\n","    project_name=\"yout project name\",\n","    workspace=\"your workspace name\",\n","    log_git_metadata=False, log_git_patch=False,display_summary_level = 0,\n",")\n","experiment.set_name(f\"your experiment name\")\n","experiment.add_tags([\"test\",\"model_RNN\", \"my tag\"])\n"]},{"cell_type":"markdown","metadata":{},"source":["# Import Dependencies"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-20T13:43:24.919282Z","iopub.status.busy":"2024-06-20T13:43:24.918678Z","iopub.status.idle":"2024-06-20T13:43:26.672359Z","shell.execute_reply":"2024-06-20T13:43:26.671201Z","shell.execute_reply.started":"2024-06-20T13:43:24.919240Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["# Define Parameters"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-20T13:43:49.095236Z","iopub.status.busy":"2024-06-20T13:43:49.094785Z","iopub.status.idle":"2024-06-20T13:43:49.194280Z","shell.execute_reply":"2024-06-20T13:43:49.193192Z","shell.execute_reply.started":"2024-06-20T13:43:49.095203Z"},"trusted":true},"outputs":[],"source":["hyper_params = {\"batch_size\": 100, \"num_epochs\": 3, \"learning_rate\": 0.01}\n","experiment.log_parameters(hyper_params)"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-20T13:43:50.474354Z","iopub.status.busy":"2024-06-20T13:43:50.473795Z","iopub.status.idle":"2024-06-20T13:43:59.144174Z","shell.execute_reply":"2024-06-20T13:43:59.142787Z","shell.execute_reply.started":"2024-06-20T13:43:50.474309Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:03<00:00, 2509329.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 333794.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 2685296.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 1844194.46it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# MNIST Dataset\n","train_dataset = datasets.MNIST(\n","    root=\"./data/\", train=True, transform=transforms.ToTensor(), download=True\n",")\n","\n","test_dataset = datasets.MNIST(\n","    root=\"./data/\", train=False, transform=transforms.ToTensor()\n",")\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(\n","    dataset=train_dataset, batch_size=hyper_params[\"batch_size\"], shuffle=True\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    dataset=test_dataset, batch_size=hyper_params[\"batch_size\"], shuffle=False\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Define Model and Optimizer"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-20T13:44:04.644235Z","iopub.status.busy":"2024-06-20T13:44:04.643827Z","iopub.status.idle":"2024-06-20T13:44:04.683303Z","shell.execute_reply":"2024-06-20T13:44:04.682189Z","shell.execute_reply.started":"2024-06-20T13:44:04.644203Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(9216, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","\n","        return x\n","\n","\n","model = Net().to(device)\n","\n","# Loss and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=hyper_params[\"learning_rate\"])"]},{"cell_type":"markdown","metadata":{},"source":["# Train a Model"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-20T13:44:25.932295Z","iopub.status.busy":"2024-06-20T13:44:25.931859Z","iopub.status.idle":"2024-06-20T13:44:25.944658Z","shell.execute_reply":"2024-06-20T13:44:25.942993Z","shell.execute_reply.started":"2024-06-20T13:44:25.932261Z"},"trusted":true},"outputs":[],"source":["def train(model, optimizer, criterion, dataloader, epoch, experiment):\n","    model.train()\n","    total_loss = 0\n","    correct = 0\n","    for batch_idx, (images, labels) in enumerate(\n","        tqdm(dataloader, total=len(dataloader))\n","    ):\n","        optimizer.zero_grad()\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = model(images)\n","\n","        loss = criterion(outputs, labels)\n","        pred = outputs.argmax(\n","            dim=1, keepdim=True\n","        )  # get the index of the max log-probability\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Compute train accuracy\n","        batch_correct = pred.eq(labels.view_as(pred)).sum().item()\n","        batch_total = labels.size(0)\n","\n","        total_loss += loss.item()\n","        correct += batch_correct\n","\n","        # Log batch_accuracy to Comet; step is each batch\n","        experiment.log_metric(\"batch_accuracy\", batch_correct / batch_total)\n","\n","    total_loss /= len(dataloader.dataset)\n","    correct /= len(dataloader.dataset)\n","\n","    experiment.log_metrics({\"accuracy\": correct, \"loss\": total_loss}, epoch=epoch)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-20T13:44:33.559893Z","iopub.status.busy":"2024-06-20T13:44:33.559371Z","iopub.status.idle":"2024-06-20T13:50:01.817202Z","shell.execute_reply":"2024-06-20T13:50:01.815960Z","shell.execute_reply.started":"2024-06-20T13:44:33.559851Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running Model Training\n","Epoch: 0/3\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 600/600 [01:18<00:00,  7.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1/3\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 600/600 [01:23<00:00,  7.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2/3\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 600/600 [01:22<00:00,  7.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3/3\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 600/600 [01:23<00:00,  7.18it/s]\n"]}],"source":["# Train the Model\n","print(\"Running Model Training\")\n","\n","max_epochs = hyper_params[\"num_epochs\"]\n","with experiment.train():\n","    watch(model)\n","    for epoch in range(max_epochs + 1):\n","        print(\"Epoch: {}/{}\".format(epoch, max_epochs))\n","        train(model, optimizer, criterion, train_loader, epoch, experiment)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def test(model, optimizer, criterion, dataloader, epoch, experiment):\n","    model.eval()\n","\n","    total_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for batch_idx, (images, labels) in tqdm(enumerate(dataloader)):\n","            images, labels = images.to(device), labels.to(device)\n","            output = model(images)\n","            total_loss += criterion(output, labels).item()  # sum up batch loss\n","            pred = output.argmax(\n","                dim=1,\n","                keepdim=True,\n","            )  # get the index of the max log-probability\n","            correct += pred.eq(labels.view_as(pred)).sum().item()\n","\n","        total_loss /= len(dataloader.dataset)\n","        correct /= len(dataloader.dataset)\n","\n","        experiment.log_metrics({\"accuracy\": correct, \"loss\": total_loss}, epoch=epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Test the Model\n","print(\"Running Model Evaluation\")\n","\n","with experiment.test():\n","    test(model, optimizer, criterion, test_loader, epoch, experiment)"]},{"cell_type":"markdown","metadata":{},"source":["# Log the Model to Comet"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from comet_ml.integration.pytorch import log_model\n","\n","log_model(experiment, model, \"Pytorch-Net-FashionMNIST\")"]},{"cell_type":"markdown","metadata":{},"source":["# End Experiment "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["experiment.end()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
